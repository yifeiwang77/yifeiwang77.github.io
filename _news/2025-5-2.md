---
layout: post
date: 2025-5-1
inline: true
related_posts: false
---

3 papers were accepted at ICML 2025. We inverstigated how [position bias](https://www.arxiv.org/pdf/2502.01951) emerges in Transformers (lost-in-the-middle, attention sink, RoPE) and how to improve length generalization with [output alignment](https://openreview.net/pdf?id=sxL3irchez). We also proposed [CSR](https://www.arxiv.org/pdf/2503.01776) as a new paradigm to attain adaptive embeddings with sparsity.