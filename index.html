<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Yifei Wang </title> <meta name="author" content="Yifei Wang"> <meta name="description" content="Postdoc at MIT CSAIL. "> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="/assets/img/favicon-192x192.png?df45a378aa715da8c29ebd47ed713002"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://yifeiwang77.github.io/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item active"> <a class="nav-link" href="/">about <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">research </a> </li> <li class="nav-item "> <a class="nav-link" href="/service/">service </a> </li> <li class="nav-item "> <a class="nav-link" href="/talks/">talks </a> </li> <li class="nav-item "> <a class="nav-link" href="/misc/">misc </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title"> <span class="font-weight-bold">Yifei</span> Wang <span style="color: var(--global-theme-color);">(on the job market!) </span> </h1> <p class="desc">Postdoc at <a href="https://www.csail.mit.edu/" rel="external nofollow noopener" target="_blank">MIT CSAIL</a></p> </header> <article> <div class="profile float-right"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/avatar.JPG" sizes="(min-width: 930px) 270.0px, (min-width: 576px) 30vw, 95vw"> <img src="/assets/img/avatar.JPG?27fe5d7b4db363c35628ecea99112d66" class="img-fluid z-depth-1 rounded" width="100%" height="auto" alt="avatar.JPG" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </source></picture> </figure> </div> <div class="clearfix"> <p>I am a machine learning researcher at MIT CSAIL, advised by <a href="https://people.csail.mit.edu/stefje/" rel="external nofollow noopener" target="_blank">Stefanie Jegelka</a>. My research has contributed to theoretical principles of foundation models (generative and representation models) and efficient algorithms for model capabilities and safety:</p> <ul> <li> <strong>Mathematical Principles of Foundation Models</strong>. I developed theoretical foundations for a broad spectrum of self-supervised learning (SSL) methods used in pretraining, encompassing contrastive [<a href="http://arxiv.org/pdf/2203.13457" rel="external nofollow noopener" target="_blank">1</a>, <a href="https://openreview.net/pdf?id=VBTJqqWjxMv" rel="external nofollow noopener" target="_blank">2</a>], non-contrastive [<a href="https://openreview.net/pdf?id=cIbjyd2Vcy" rel="external nofollow noopener" target="_blank">3</a>], reconstructive [<a href="https://arxiv.org/pdf/2210.08344" rel="external nofollow noopener" target="_blank">4</a>], autoregressive [<a href="https://openreview.net/pdf?id=2rPoTgEmjV" rel="external nofollow noopener" target="_blank">5</a>], and predictive [<a href="https://openreview.net/pdf?id=yLpuruMZHE" rel="external nofollow noopener" target="_blank">6</a>, <a href="https://arxiv.org/pdf/2102.10739" rel="external nofollow noopener" target="_blank">7</a>] approaches. I also analyzed the feature dynamics in deep neural networks [<a href="https://openreview.net/pdf?id=7eFS8aZHAM" rel="external nofollow noopener" target="_blank">8</a>, <a href="https://arxiv.org/pdf/2405.18781" rel="external nofollow noopener" target="_blank">9</a>] and pioneered a rigorous understanding [<a href="https://arxiv.org/pdf/2405.18634" rel="external nofollow noopener" target="_blank">10</a>] of LLMs’ self-correction ability, a critical component for test-time reasoning.</li> <li> <strong>Improving Model Capabilities</strong>. I leveraged these principles to “debug” foundation models. I addressed the rank collapse issue in neural networks [<a href="https://arxiv.org/pdf/2311.02687.pdf" rel="external nofollow noopener" target="_blank">11</a>, <a href="https://proceedings.mlr.press/v162/chen22z/chen22z.pdf" rel="external nofollow noopener" target="_blank">12</a>], generalized self-supervised learning with unsupervised world models [<a href="https://arxiv.org/pdf/2405.18193" rel="external nofollow noopener" target="_blank">13</a>]; alleviated data shortage by adaptively utilizing AI-generated data [<a href="https://arxiv.org/pdf/2403.12448.pdf" rel="external nofollow noopener" target="_blank">14</a>], and enhanced LLM long-context understanding with novel perplexity measures [<a href="https://arxiv.org/pdf/2410.23771" rel="external nofollow noopener" target="_blank">15</a>].</li> <li> <strong>Trustworthy Foundation Models</strong>. I contributed to theory-inspired algorithms to build trustworthy foundation models with respect to adversarial robustness [<a href="http://arxiv.org/pdf/2203.13455" rel="external nofollow noopener" target="_blank">16</a>, <a href="https://arxiv.org/pdf/2210.07540.pdf" rel="external nofollow noopener" target="_blank">17</a>, <a href="https://arxiv.org/pdf/2310.19360.pdf" rel="external nofollow noopener" target="_blank">18</a>, <a href="https://arxiv.org/pdf/2310.18936.pdf" rel="external nofollow noopener" target="_blank">11</a>], feature interpretability [<a href="https://arxiv.org/pdf/2310.18904.pdf" rel="external nofollow noopener" target="_blank">19</a>, <a href="https://arxiv.org/pdf/2403.12459" rel="external nofollow noopener" target="_blank">20</a>], and domain generalization [<a href="https://arxiv.org/pdf/2210.06807" rel="external nofollow noopener" target="_blank">21</a>, <a href="https://arxiv.org/pdf/2212.09082.pdf" rel="external nofollow noopener" target="_blank">22</a>, <a href="https://arxiv.org/pdf/2310.12793" rel="external nofollow noopener" target="_blank">23</a>]. In particular, I contributed to the use of LLMs’ own emergent abilities (such as in-context learning [<a href="https://arxiv.org/pdf/2310.06387" rel="external nofollow noopener" target="_blank">24</a>] and self-correction [<a href="https://arxiv.org/pdf/2405.18634" rel="external nofollow noopener" target="_blank">10</a>]) for jailbreaking and defending LLMs (featured and scaled up by <a href="https://www.anthropic.com/research/many-shot-jailbreaking" rel="external nofollow noopener" target="_blank">Anthropic</a>).</li> </ul> <p>My first-author papers received the Best ML Paper Award at ECML-PKDD 2021, the Silver Best Paper Award at ICML 2021 AdvML workshop, and the Best Paper Award at ICML 2024 ICL workshop. My thesis won the CAAI Outstanding Ph.D. Dissertation Runner-Up Award. I published 33 papers at NeurIPS, ICLR, and ICML, and I am a (co)-first author on 22 of them.</p> <p>I served as an area chair for ICLR 2024 and 2025 and as a regular reviewer for main AI/ML conferences (NeurIPS, ICML, ECML, AISTATS, LoG, CVPR, ACL). I co-organized the <a href="https://redteaming-gen-ai.github.io/" rel="external nofollow noopener" target="_blank">NeurIPS 2024 Workshop on Red Teaming GenAI</a> and the <a href="https://projects.csail.mit.edu/ml-tea/" rel="external nofollow noopener" target="_blank">MIT ML Tea Seminar</a>.</p> <p>I obtained my PhD in Applied Mathematics from Peking University in 2023, advised by <a href="https://yisenwang.github.io" rel="external nofollow noopener" target="_blank">Yisen Wang</a>, <a href="https://zhouchenlin.github.io/" rel="external nofollow noopener" target="_blank">Zhouchen Lin</a>, <a href="https://www.math.pku.edu.cn/jsdw/js_20180628175159671361/y_20180628175159671361/69984.htm" rel="external nofollow noopener" target="_blank">Jiansheng Yang</a>. Prior to that, I did my undergraduate at School of Mathematical Sciences, Peking University.</p> <div class="social"> <div class="contact-icons"> <a href="mailto:%79%69%66%65%69_%77@%6D%69%74.%65%64%75" title="email"><i class="fa-solid fa-envelope"></i></a> <a href="https://scholar.google.com/citations?user=CLy6YsAAAAJ" title="Google Scholar" rel="external nofollow noopener" target="_blank"><i class="ai ai-google-scholar"></i></a> <a href="https://github.com/yifeiwang77" title="GitHub" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-github"></i></a> <a href="https://www.linkedin.com/in/yifeiwang77" title="LinkedIn" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-linkedin"></i></a> <a href="https://twitter.com/yifeiwang77" title="X" rel="external nofollow noopener" target="_blank"><i class="fa-brands fa-x-twitter"></i></a> </div> <div class="contact-note"></div> </div> </div> <h2> <a href="/news/" style="color: inherit">news</a> </h2> <div class="news"> <div class="table-responsive" style="max-height: 60vw"> <table class="table table-sm table-borderless"> <tr> <th scope="row" style="width: 20%">December, 2024</th> <td> I gave a talk on <em>Principles of Foundations Models</em> at Johns Hopkins University. </td> </tr> <tr> <th scope="row" style="width: 20%">November, 2024</th> <td> I gave a guest lecture on <em>Towards Test-time Self-supervised Learning</em> (<a href="assets/pdf/TT-SSL-talk-Nov2024.pdf">slides</a>) at Boston College. </td> </tr> <tr> <th scope="row" style="width: 20%">October, 2024</th> <td> 3 new preprints are out, exploring 1) how existing long-context training of LLMs is problematic and how to address it (<a href="https://arxiv.org/pdf/2410.23771" rel="external nofollow noopener" target="_blank">paper</a>), 2) how sparse autoencoders can significantly improve robustness at noisy and few-shot scenarios (<a href="https://arxiv.org/pdf/2410.21331" rel="external nofollow noopener" target="_blank">paper</a>), and 3) whether ICL can truly extrapolate to OOD scenarios (<a href="https://arxiv.org/pdf/2410.09695" rel="external nofollow noopener" target="_blank">paper</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">October, 2024</th> <td> 6 papers were accepted to NeurIPS 2024. We inverstigated <em>how LLMs perform self-correction at test time</em> (<a href="https://arxiv.org/pdf/2405.18634" rel="external nofollow noopener" target="_blank">paper</a>), how to build <em>dynamic world models</em> through joint embedding methods (<a href="https://arxiv.org/pdf/2405.18193" rel="external nofollow noopener" target="_blank">paper</a>), how Transformers avoid feature collapse with LayerNorm and attention masks (<a href="https://arxiv.org/pdf/2405.18781" rel="external nofollow noopener" target="_blank">paper</a>), and why equivariant prediction of data corruptions helps learn good representations (<a href="https://openreview.net/pdf?id=NLqdudgBfy" rel="external nofollow noopener" target="_blank">paper</a>). </td> </tr> <tr> <th scope="row" style="width: 20%">September, 2024</th> <td> I gave a talk at NYU Tandon on Building Safe Foundation Models from Principled Understanding. </td> </tr> <tr> <th scope="row" style="width: 20%">August, 2024</th> <td> I gave a talk at Princeton University on Reimagining Self-Supervised Learning with Context. </td> </tr> </table> </div> </div> <h2> <a href="/publications/" style="color: inherit">selected publications</a> </h2> <div class="publications"> <ol class="bibliography"> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <special class="badge rounded w-100">LLM training &amp; eval</special> </div> <div id="fang2024perplexity" class="col-sm-8"> <div class="title">What is Wrong with Perplexity for Long-context Language Modeling?</div> <div class="author"> Lizhe Fang<sup>*</sup>,  <u>Yifei Wang</u><sup>*</sup>, Zhaoyang Liu, Chenheng Zhang, Stefanie Jegelka, Jinyang Gao, Bolin Ding, and Yisen Wang </div> <div class="periodical"> <em>arXiv preprint arXiv:2410.23771</em>, 2024 </div> <div class="periodical"> We proposed a long-context perplexity measure that emphasizes long-context relevant tokens at training and evaluation, improving benchmark scores on LongBench, LongEval, and RULER by up to 22%. </div> <div class="links"> <a href="https://arxiv.org/pdf/2405.18634" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PKU-ML/LongPPL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <special class="badge rounded w-100">Best Paper Award<br> at ICML-W’24</special> </div> <div id="wang2024theoretical" class="col-sm-8"> <div class="title">A Theoretical Understanding of Self-Correction through In-context Alignment</div> <div class="author"> <u>Yifei Wang</u><sup>*</sup>, Yuyang Wu<sup>*</sup>, Zeming Wei, Stefanie Jegelka, and Yisen Wang </div> <div class="periodical"> <em>In NeurIPS</em>, 2024 </div> <div class="periodical"> <span style="font-weight: bold;">Best Paper Award</span> at ICML 2024 ICL Workshop<br> We proposed the first theoretical explanation of how LLM self-correction works (as in OpenAI o1) and showed its effectiveness against social bias and jailbreak attacks. </div> <div class="links"> <a href="https://arxiv.org/pdf/2405.18634" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yifeiwang77/Self-Correction" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <special class="badge rounded w-100">Oral at NeurIPS-W’24</special> </div> <div id="wang2024symmetries" class="col-sm-8"> <div class="title">In-Context Symmetries: Self-Supervised Learning through Contextual World Models</div> <div class="author"> Sharut Gupta<sup>*</sup>, Chenyu Wang<sup>*</sup>,  <u>Yifei Wang</u><sup>*</sup>, Tommi Jaakkola, and Stefanie Jegelka </div> <div class="periodical"> <em>In NeurIPS</em>, 2024 </div> <div class="periodical"> <span style="font-weight: bold;">Oral Presentation (top 4)</span> at NeurIPS 2024 SSL Workshop<br> We introduced unsupervised test-time adaptation ability to self-supervised learning through a contextual world model designed for joint embedding (JEPA) models. </div> <div class="links"> <a href="https://arxiv.org/pdf/2405.18193" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/Sharut/In-Context-Symmetries" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">arXiv</abbr> <special class="badge rounded w-100">Featured by Anthropic</special> </div> <div id="wei2023jailbreak" class="col-sm-8"> <div class="title">Jailbreak and guard aligned language models with only few in-context demonstrations</div> <div class="author"> Zeming Wei,  <u>Yifei Wang</u>, and Yisen Wang </div> <div class="periodical"> <em>arXiv preprint arXiv:2310.06387</em>, 2023 </div> <div class="periodical"> <span style="font-weight: bold;">Cited over 140 times</span>. Featured and scaled up in <a href="https://www.anthropic.com/research/many-shot-jailbreaking" target="_blank" rel="external nofollow noopener">Anthropic’s research blog</a>, where it successfully demonstrated jailbreaking prominent LLMs, including GPT and Claude. </div> <div class="links"> <a href="https://arxiv.org/pdf/2310.06387" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="wang2024nonnegative" class="col-sm-8"> <div class="title">Non-negative Contrastive Learning</div> <div class="author"> <u>Yifei Wang</u><sup>*</sup>, Qi Zhang<sup>*</sup>, Yaoyu Guo, and Yisen Wang </div> <div class="periodical"> <em>In ICLR</em>, 2024 </div> <div class="periodical"> Inspired by NMF, we introduced a one-line technique that <span style="font-weight: bold;">attains 90% feature sparsity to 90% and 10x feature interpretability</span> in contrastive learning models. </div> <div class="links"> <a href="https://arxiv.org/pdf/2403.12459" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PKU-ML/non_neg" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/NCL_LIDS_tea.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="luo2023augmentation" class="col-sm-8"> <div class="title">Rethinking the Effect of Data Augmentation in Adversarial Contrastive Learning</div> <div class="author"> Rundong Luo<sup>*</sup>,  <u>Yifei Wang</u><sup>*</sup>, and Yisen Wang </div> <div class="periodical"> <em>In ICLR</em>, 2023 </div> <div class="periodical"> We <span style="font-weight: bold;">improved adversarial robustness under AutoAttack by 9%</span> in the unsupervised setting with a dynamic training schedule, without extra computation cost. </div> <div class="links"> <a href="https://openreview.net/pdf?id=0qmwFNJyxCL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/PKU-ML/DynACL" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">NeurIPS</abbr> <special class="badge rounded w-100">Spotlight</special> </div> <div id="zhang2022mae" class="col-sm-8"> <div class="title">How Mask Matters: Towards Theoretical Understandings of Masked Autoencoders</div> <div class="author"> Qi Zhang<sup>*</sup>,  <u>Yifei Wang</u><sup>*</sup>, and Yisen Wang </div> <div class="periodical"> <em>In NeurIPS <span style="font-weight: bold;">Spotlight</span> (Top 5%)</em>, 2022 </div> <div class="periodical"> We theoretically explained how masked autoencoders work and revealed their mathematical connections to joint embedding methods, unifying them as a whole. </div> <div class="links"> <a href="https://arxiv.org/pdf/2210.08344" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zhangq327/U-MAE" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/NeurIPS2022_mae.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> </div> <div id="wang2022chaos" class="col-sm-8"> <div class="title">Chaos is a Ladder: A New Theoretical Understanding of Contrastive Learning via Augmentation Overlap</div> <div class="author"> <u>Yifei Wang</u><sup>*</sup>, Qi Zhang<sup>*</sup>, Yisen Wang, Jiansheng Yang, and Zhouchen Lin </div> <div class="periodical"> <em>In ICLR</em>, 2022 </div> <div class="periodical"> <span style="font-weight: bold;">Cited over 120 times</span>. We derived tight generalization bounds for contrastive learning with a new realistic theoretical framework. It derived unsupervised evaluation metrics with 97% correlation to downstream performance. </div> <div class="links"> <a href="http://arxiv.org/pdf/2203.13457" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/zhangq327/ARC" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/ICLR2022_overlap.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ICLR</abbr> <special class="badge rounded w-100">Silver Best Paper <br> at ICML-W’21</special> </div> <div id="wang2022cem" class="col-sm-8"> <div class="title">A Unified Contrastive Energy-based Model for Understanding the Generative Ability of Adversarial Training</div> <div class="author"> <u>Yifei Wang</u>, Yisen Wang, Jiansheng Yang, and Zhouchen Lin </div> <div class="periodical"> <em>In ICLR</em>, 2022 </div> <div class="periodical"> <span style="font-weight: bold; color: var(–global-theme-color);">Silver Best Paper Award</span> at ICML 2021 AdvML workshop<br> From an energy-based perspective, we formulated contrastive learning as a generative model, and established the connection between adversarial training and maximum likelihood, thus briding generative and discriminative models together. </div> <div class="links"> <a href="http://arxiv.org/pdf/2203.13455" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="/assets/pdf/ICLR2022_CEM.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> </div> </div> </li> <li> <div class="row"> <div class="col col-sm-2 abbr"> <abbr class="badge rounded w-100">ECML-PKDD</abbr> <special class="badge rounded w-100">Best ML Paper Award</special> </div> <div id="wang2021reparameterized" class="col-sm-8"> <div class="title">Reparameterized Sampling for Generative Adversarial Networks</div> <div class="author"> <u>Yifei Wang</u>, Yisen Wang, Jiansheng Yang, and Zhouchen Lin </div> <div class="periodical"> <em>In ECML-PKDD</em>, 2021 </div> <div class="periodical"> <span style="font-weight: bold;">Best ML Paper Award (1/685)</span>, invited to <i>Machine Learning</i><br> We explored using GAN discriminator (as a good reward model) to bootstrap sample quality through an efficient MCMC algorithm, which not only guarantees theoretical convergence but also improves sample efficiency and quality in practice. </div> <div class="links"> <a href="https://arxiv.org/pdf/2107.00352" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">PDF</a> <a href="https://github.com/yifeiwang77/repgan" class="btn btn-sm z-depth-0" role="button" rel="external nofollow noopener" target="_blank">Code</a> <a href="/assets/pdf/ECML2021_REPGAN_slides.pdf" class="btn btn-sm z-depth-0" role="button">Slides</a> </div> </div> </div> </li> </ol> </div> </article> </div> </div> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> </body> </html>