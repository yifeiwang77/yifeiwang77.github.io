---
layout: about
title: about
permalink: /

profile:
  align: right
  image: avatar.JPG
  image_circular: false # crops the image to make it circular
social: true # includes social icons at the bottom of the page
news: true # includes a list of news items
selected_papers: true # includes a list of papers marked as "selected={true}"
---


I am currently a Member of Technical Staff at the <a href="https://www.amazon.science/blog/amazon-opens-new-ai-lab-in-san-francisco-focused-on-long-term-research-bets">Amazon AGI SF Lab</a>. 
I currently focus on post-training LLMs to build more capable agents, improving their general reasoning across diverse real-world tasks including search, coding, and computer use.


<!-- My current research focuses on LLM post-training for agents, improving their general reasoning across diverse real-world agent tasks such as search, coding, and computer use. -->
<!-- My current research focuses on LLM post-training, especially improving their general reasoning abilities across diverse real-world agent tasks, including search, coding, and computer use. -->

I was a postdoc at <a href="https://www.csail.mit.edu/">MIT CSAIL</a> (2023-2025), advised by <a href="https://people.csail.mit.edu/stefje/">Stefanie Jegelka</a>.  I received my Ph.D. in Applied Mathematics from Peking University, advised by  [Yisen Wang](https://yisenwang.github.io), [Zhouchen Lin](https://zhouchenlin.github.io/), and  [Jiansheng Yang](https://www.math.pku.edu.cn/jsdw/js_20180628175159671361/y_20180628175159671361/69984.htm).  I also completed my B.S. and B.A. at Peking University.

My research interests lie broadly in unsupervised learning, representation learning, and reinforcement learning, with the overarching goal of developing more scalable and generalizable learning paradigms. My work has received [5 best paper awards](./awards) and has been featured by  [MIT News](https://news.mit.edu/2025/unpacking-large-language-model-bias-0617) and  [Anthropic](https://www.anthropic.com/research/many-shot-jailbreaking). I serve as an Area Chair for ICLR and ICML.


<!-- with application to building generic and reliable AI agents. -->
<!-- I am interested in unsupervised learning, representation learning, and reasoning.   methods for scaling foundation models  -->
<!-- with interests in unsupervised learning  -->
<!-- representation learning, reasoning, a understanding and developing scalable machine learning methods. My past research includes self-supervised learning, reasoning, -->
